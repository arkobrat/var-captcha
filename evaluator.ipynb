{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "919eba33",
   "metadata": {},
   "source": [
    "Load the Model and Label Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf213e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.1)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (res1): ResidualBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): LeakyReLU(negative_slope=0.1)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (res2): ResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): LeakyReLU(negative_slope=0.1)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (drop2): Dropout(p=0.2, inplace=False)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (res3): ResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): LeakyReLU(negative_slope=0.1)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (drop3): Dropout(p=0.3, inplace=False)\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.1)\n",
       "  (drop4): Dropout(p=0.4, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act3): LeakyReLU(negative_slope=0.1)\n",
       "  (drop5): Dropout(p=0.4, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from model.model import EnhancedModel  # adjust import if needed\n",
    "\n",
    "# Load label binarizer\n",
    "with open(\"model//model_labels.dat\", \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "# Load model\n",
    "num_classes = 36\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnhancedModel(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"model//captcha_recognition_model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fef0d",
   "metadata": {},
   "source": [
    "Prepare the Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02677b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from model.model import CaptchaDataset  # adjust import if needed\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Recreate test_samples as in your training script\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "LETTER_IMAGES_FOLDER = \"extracted_characters\"\n",
    "all_samples = []\n",
    "for label in os.listdir(LETTER_IMAGES_FOLDER):\n",
    "    label_folder = os.path.join(LETTER_IMAGES_FOLDER, label)\n",
    "    if os.path.isdir(label_folder):\n",
    "        for image_file in os.listdir(label_folder):\n",
    "            image_path = os.path.join(label_folder, image_file)\n",
    "            all_samples.append((image_path, label))\n",
    "\n",
    "_, test_samples = train_test_split(all_samples, test_size=0.25, random_state=42)\n",
    "test_dataset = CaptchaDataset(test_samples, lb, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75319b",
   "metadata": {},
   "source": [
    "Run Inference and Collect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8e960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(torch.sigmoid(outputs), dim=1)\n",
    "        targets = torch.argmax(labels, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74003b",
   "metadata": {},
   "source": [
    "Compute Precision, Recall, and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac3498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9182\n",
      "Recall:    0.9137\n",
      "F1 Score:  0.9146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(all_targets, all_preds, average='macro')\n",
    "recall = recall_score(all_targets, all_preds, average='macro')\n",
    "f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
